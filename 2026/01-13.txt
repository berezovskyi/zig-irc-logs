1768270576
goodtab!~goodtab@user/goodtab
was seeing 'opencode' all over my Twitter feed, it's claude code but open. i was really admiring their TUI and had to see the sauce... turns out their TUI lib (opentui) is built on Zig!

1768270606
andrewrk!~andrewrk@mail.ziglang.org
is rockorager involved?

1768270644
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
Not me

1768270674
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
Though the guy who wrote the zig part of that did talk to me about some things

1768270706
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
But I am dominating the typescript world with zig now :jo

1768270710
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
üòÇ

1768270750
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
The tooling is so slow but I can basically tell AI to rewrite it in zig for me and get an immediate 30x speed boost in testing

1768270766
andrewrk!~andrewrk@mail.ziglang.org
lol

1768270768
goodtab!~goodtab@user/goodtab
that's pretty freakin' awesome

1768270891
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
https://github.com/ampcode/zvelte-check

1768270898
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
I wrote that one this past ~week

1768270947
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
"wrote"

1768270988
LAC-Tech!~lewis@granite-phrase.bnr.la
do they have a test suite?

1768270998
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
Yeah

1768271025
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
For svelte 5, this passes all with one failure that is semantically the same, just a different error text because it's using tsgo instead of tsc

1768271130
LAC-Tech!~lewis@granite-phrase.bnr.la
nice. I am enjoying the new era of native tooling for JS/TS. I opened a script of mine that was like.. 300 LOC, and I could feel a noticable delay when formatted on save with prettier. replaced it with that oxfmt thing, and it just felt normal

1768271167
LAC-Tech!~lewis@granite-phrase.bnr.la
do the svelte folks like it?

1768271176
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
 ÃÑ\_(„ÉÑ)_/ ÃÑ

1768271183
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
We're using it in our CI now

1768271191
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
it's only 4 days old

1768271213
LAC-Tech!~lewis@granite-phrase.bnr.la
I would personally be delighted if someone replaced something I wrote, with the same functionality, and it was 30x faster. but peoples egos can be weird lol

1768271404
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
i'm having AI rewrite the typescript compiler in zig too, I somehow doubt microsoft will be thrilled when I've made a faster compiler than them in just a few days lol

1768271588
LAC-Tech!~lewis@granite-phrase.bnr.la
hahaah

1768271599
LAC-Tech!~lewis@granite-phrase.bnr.la
I mean tbh I would be surprised if it works...

1768271857
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
lol yeah we'll see

1768271864
rvrb!~rvrb@156.146.51.230
honestly, 6 months ago I would have too, but something happened in the last couple of months

1768271875
rvrb!~rvrb@156.146.51.230
it's gettin weird out there

1768271880
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
i'm at 40.2% compliance right now

1768272088
LAC-Tech!~lewis@granite-phrase.bnr.la
rvrb: IDK maybe I am just "holding it wrong" but I used everyones favourite new models and they weren't that great. there's a lot of grift and hype

1768272142
rvrb!~rvrb@156.146.51.230
Claude Code + Opus 4.5, a well defined, well explored problem, and a text-based feedback loop.. vibing a TypeScript compiler is totally doable 

1768272189
rvrb!~rvrb@156.146.51.230
it's not like it can create new ideas or something but it does very well with positive reinforcement loops 

1768272201
rvrb!~rvrb@156.146.51.230
so yeah I can see a TypeScript compiler working

1768272365
torque!~tachyon@user/torque
please vibe code a faster zig compiler whilst you are at it, to prove a point about something

1768272425
LAC-Tech!~lewis@granite-phrase.bnr.la
rvrb: right so this is more... interactive LLM usage. not "LOL claude write me a compiler". yeah ok that is possible.

1768272444
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
no this is ‚Äúlol write me a compiler‚Äù

1768272450
rvrb!~rvrb@156.146.51.230
lol

1768272481
rockorager!~rockorage@2600:3c06::f03c:94ff:fea6:1f08
i havent read any code, i run in a loop where its just fixing conformance issue. run the test, fix the bug. keep going

1768272487
LAC-Tech!~lewis@granite-phrase.bnr.la
well... let me know how far it gets :) I am very skeptical. a friend of mine wasted a lot of token money trying to do something similar for lols

1768272503
rvrb!~rvrb@156.146.51.230
the reason I know this is because I tried "lol write me an email client" last week, and within an hour or two I was reading my email in a vibe coded email client

1768272504
LAC-Tech!~lewis@granite-phrase.bnr.la
*much simpler

1768272531
LAC-Tech!~lewis@granite-phrase.bnr.la
huh, mabye I am just asking it to make the wrong things

1768272565
rvrb!~rvrb@156.146.51.230
rendering with GPUI (the Zed UI engine), parsing/converting HTML/CSS

1768272986
andrewrk!~andrewrk@mail.ziglang.org
I'd rather sniff my own farts than review llm generated code

1768273127
clevor!sid649024@id-649024.hampstead.irccloud.com
My main thought was "AI üò¨" but now it's "AI üò®"

1768273435
torque!~tachyon@user/torque
i'm not a subject matter expert, but as far as I could tell from the conversation, the point of using an LLM is to troll other people by making them review your LLM code, which you do not actually ever look at yourself

1768273476
rvrb!~rvrb@156.146.51.230
right, it definitely seems insane to push LLM generated code to a human to review

1768273510
rvrb!~rvrb@156.146.51.230
and I don't know where that leaves us. but my point stands, they're getting weird

1768273639
rvrb!~rvrb@156.146.51.230
I've been entertaining a blog post titled "weapons of mass construction" exploring the parallels of MAD, WMD, etc

1768273825
LAC-Tech!~lewis@granite-phrase.bnr.la
I was recently challenged by a very angry vibe coding CEO/youtuber to a 20k USD "coding challenge", whatever that means. so yeah people get very sensitive about it.

1768273867
andrewrk!~andrewrk@mail.ziglang.org
1. form an LLC

1768273869
torque!~tachyon@user/torque
i suspect the challenge is something along the lines of he does it with an llm and you do it without an llm and you see who wins

1768273874
andrewrk!~andrewrk@mail.ziglang.org
2. sign contract agreeing to the terms

1768273879
andrewrk!~andrewrk@mail.ziglang.org
3. declare bankruptcy if you lose

1768274036
LAC-Tech!~lewis@granite-phrase.bnr.la
it's the primageans junior programmer friend. but andrewrk that is very sage advice :)

1768274062
clevor!sid649024@id-649024.hampstead.irccloud.com
One aspect of vibe coding and using AI in general is whether you prefer to work on something, or to have the work finished.

1768274111
LAC-Tech!~lewis@granite-phrase.bnr.la
right. vibe coding can start you off. it's like those "starter repo" things on steroids. but after that... things fall off a cliff

1768274209
andrewrk!~andrewrk@mail.ziglang.org
I haven't tried the fancy tools because too much of my soul is intact to give megacorp control over my coding environment

1768274315
clevor!sid649024@id-649024.hampstead.irccloud.com
Those who only see coding as something to do are going to have a hard time understanding those who see coding as something to be doing.

1768274331
torque!~tachyon@user/torque
get bun to get anthropic to sponsor the zig core team so you can enjoy working with your new favorite team mate, claude

1768274408
andrewrk!~andrewrk@mail.ziglang.org
I wouldn't give up programming for 10 billion dollars

1768274443
LAC-Tech!~lewis@granite-phrase.bnr.la
andrewrk: I don't see them having much benefit if you're a domain expert in a niche thing... like a zig compiler lol

1768274510
rvrb!~rvrb@156.146.51.230
What I like about the LLMs is that the people like you will stay around and the people that aren‚Äôt will not, andrewrk

1768274544
rvrb!~rvrb@156.146.51.230
Does that make sense? I got a huge amount of burnout being surrounded by people who aren‚Äôt interested in the craft itself

1768274561
LAC-Tech!~lewis@granite-phrase.bnr.la
yeah that is a huge part of the divide

1768274575
LAC-Tech!~lewis@granite-phrase.bnr.la
I mean people were doing slop code before, but now it's easier

1768274773
torque!~tachyon@user/torque
my take is that llms really enable people who were already generating dogshit to generate much bigger volumes of it. i really doubt that people who care to understand and design things get much of a boost out of it

1768274805
torque!~tachyon@user/torque
having continued to abstain from touching an llm at work, I haven't felt like my productivity has suffered relative to my coworkers, at least

1768274889
LAC-Tech!~lewis@granite-phrase.bnr.la
there's the 2025 study that showed it was placebo for that particular experiment, and people were actually less productive but thought they were more

1768275591
clevor!sid649024@id-649024.hampstead.irccloud.com
On  Saturday and Sunday, I worked on an IRC bot in Zig, including parsing every single message type, only to realize I massively overcomplicated it, so I restarted the project this morning. Within a few hours, I got 80% of the features I wanted to add done, which is 80% more than the previous two days. TBH I don't know if it can maintain ops since the only (2) channels it is on are either opless or single-handedly held up by someone 

1768275591
clevor!sid649024@id-649024.hampstead.irccloud.com
who doesn't use IRC anymore AFAICT

1768275856
andrewrk!~andrewrk@mail.ziglang.org
rvrb: not sure I follow, are you suggesting that most programmers will switch careers?

1768275958
LAC-Tech!~lewis@granite-phrase.bnr.la
I had a 

1768275989
LAC-Tech!~lewis@granite-phrase.bnr.la
I had a vibe code cleanup contract last year. not bad, would do it again

1768276842
rvrb!~rvrb@156.146.51.230
andrewrk: I think a majority of the industry that was built in the 2010s will shift toward mass production; and the people left hand writing code will be highly specialized, or craft/hobbyists/enthusiasts

1768276924
rvrb!~rvrb@156.146.51.230
I don't know how I feel about it, but I can't see how it won't end up that way. so at least one positive is that I will not be surrounded by people who went through code schools to get six figure salaries

1768276990
andrewrk!~andrewrk@mail.ziglang.org
I see

1768277038
andrewrk!~andrewrk@mail.ziglang.org
I guess most software out there is CRUD and LLMs are good enough at that, that companies will use them for that. I think we need anti bug regulations though. consumers need to be protected from software bugs

1768277346
rvrb!~rvrb@156.146.51.230
that's an interesting point and I agree with that, I wonder if LLMs will shepherd that era in.. but we'll probably have to suffer through 5-10 years of horrible vulnerabilities

1768318322
Smithx10!sid243404@id-243404.helmsley.irccloud.com
I don't believe in LLMs until they make money.

1768319725
reykjalin!7e28cf3a41@user/reykjalin
I‚Äôve been finding that AI is very useful to get through low-effort ideas or tools that I want but don‚Äôt find engaging to build. for example I like managing my work week in a specific way, so I‚Äôve been having an AI write it for me over the past week or so and actually have something usable already. whereas I‚Äôve started the project multiple times before but never got it to a useful point because I 

1768319726
reykjalin!7e28cf3a41@user/reykjalin
got bored

1768319750
reykjalin!7e28cf3a41@user/reykjalin
fills that niche of ‚Äúthis would be useful for me, but it‚Äôs not in my area of interest so I don‚Äôt really want to build it‚Äù

1768319864
Smithx10!sid243404@id-243404.helmsley.irccloud.com
@reykjalin do you write software for work or on your own projects?

1768319891
reykjalin!7e28cf3a41@user/reykjalin
that‚Äôs an inclusive yes üòÖ

1768319950
reykjalin!7e28cf3a41@user/reykjalin
full-stack web developer as a job, writing code by hand for projects I‚Äôm interested in, AI for things I want but dont want to spend time on - or would rather spend that time on other projects or with my family

1768320057
bblack!~bblack@wikimedia/bblack-WMF
I feel like, in cases where LLMs seem to "make sense" (as in, seem to produce an acceptable result with less effort), it's really just a symptom of something else gone wrong at a completely different level.

1768320121
bblack!~bblack@wikimedia/bblack-WMF
e.g. where that replaces the output of a human worker... you have to wonder: if the LLM can do it just as well, was the job ever worth doing, or having a human do, or both?

1768320187
bblack!~bblack@wikimedia/bblack-WMF
a whole lot of people in the world work on things that are ultimately pointless from some larger view, or where the quality really doesn't seem to matter in the end

1768320192
reykjalin!7e28cf3a41@user/reykjalin
I‚Äôve had mixed results. LLMs definitely can‚Äôt do the job at the same level as people can at this point. They need a lot of hand-holding to get to what I would deem a production ready result. LLMs are incredibly powerful prototyping tools though 

1768320679
bblack!~bblack@wikimedia/bblack-WMF
my primary defensible reason for avoiding LLMs like the plague is: even if they were super-awesome, I don't want my thinking/skillset to atrophy from disuse.  Whatever future may be coming, I want to be one of the few that still knows how to do without them, rather than one of the ones that became dependent on them.

1768320704
geenvoud!~geenvoud@user/geenvoud
bblack: indeed, this 'innovation' reminds me of the java world ide-generated getters and setters; instead of asking why do we insist on having all these trivial getters and setters, it's easier to just automate the stagnant local optimum

1768320825
Smithx10!sid243404@id-243404.helmsley.irccloud.com
I just have a feeling that the $ to Usefulness to Confidence is going to sky rocket

1768320836
Smithx10!sid243404@id-243404.helmsley.irccloud.com
right now its almost free...

1768321329
bblack!~bblack@wikimedia/bblack-WMF
on a completely unrelated topic: it's fascinating for me to see how the std.Io abstractions are playing out, as a slightly-higher-level and saner abstraction over all the "reasonable" use-cases on "reasonable" extant platforms.  I think a whole lot of important human toil is happening along the way that's making sense of the entire landscape in a way that's somewhat novel.

1768321387
bblack!~bblack@wikimedia/bblack-WMF
and I think a really interesting future outcome, will be when someone writes a new OS kernel (probably in Zig) and shapes the OS's native interfaces to match the landscape that Zig std.Io already discovered, but with fewer hisorical oddities and warts...

1768321730
bblack!~bblack@wikimedia/bblack-WMF
it's also fertile ground to blur the lines and build more unikernel-like things as std.Io abstractions right over the hardware.

1768324399
bblack!~bblack@wikimedia/bblack-WMF
is there some fundamental reason I'm failing to grasp, that there's no `fn concurrent()` in Io.Select()?

1768325263
Smithx10!sid243404@id-243404.helmsley.irccloud.com
I think the LLM models need to either not be central (learn locally from how I work and be free) or the $$$$ required to train / power etc will eventually catch up to them and just make it not profitable.    The saddest thing for me tho.... is we can have Nuclear Power for AI Datacenters and War Ships but not cities or towns since the 80s.  They stopped building them because we *had too much power*,   That's a real travesty.  

1768329471
andrewrk!~andrewrk@mail.ziglang.org
bblack: check out this related short story by Isaac Asimov: https://web.archive.org/web/20201109034130/https://www.abelard.org/asimov.php

1768332527
rvrb!~rvrb@156.146.51.230
I wrote a pretty simple reactive signal library (a la Solid.js) with std.Io support, and it is kinda neat. recomputing effects in parallel with tasks when threaded or synchronous when not

1768332581
rvrb!~rvrb@156.146.51.230
one of the things that confused me, though, when thinking in terms of std.Io is an interface.. is using data structures like mutex etc. there's no like io.isSynchronous() or anything afaict; it feels worng to add overhead when unnecessary

1768332596
rvrb!~rvrb@156.146.51.230
I am probably missing something

1768332784
rvrb!~rvrb@156.146.51.230
oh am I supposed to be using std.Io.Mutex? does that get erased in that case?

1768332871
andrewrk!~andrewrk@mail.ziglang.org
yes

1768332875
rvrb!~rvrb@156.146.51.230
what about lockless algorithms adding unnecessary atomic overhead? is there gonna be a std.Io.AtomicValue or something?

1768332899
andrewrk!~andrewrk@mail.ziglang.org
atomics and I/O operations do not need to be aware of each other, precisely because atomics are lock-free and therefore non-blocking

1768333476
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
Is this the right way to implement a writer with the new approach: https://zigbin.io/24de05

1768333613
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
I only really want formatted printing. Is it safe to ignore the other parts of the interface like splat and so on?

1768333949
andrewrk!~andrewrk@mail.ziglang.org
ii8: no it's not safe to ignore splat, it will result in wrong data

1768334022
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
ah dang

1768334030
andrewrk!~andrewrk@mail.ziglang.org
just loop from data[0..data.len - 1] instead, then loop again for (0..splat) |_| and write data[data.len - 1] that many times

1768334170
andrewrk!~andrewrk@mail.ziglang.org
btw rvrb whatever happened to your multiple allocations API that you made that one time? I've needed that like 6 times now

1768334170
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
Alright thanks.

1768334833
andrewrk!~andrewrk@mail.ziglang.org
oh I found it: https://github.com/tristanpemble/resizable-struct

1768334843
andrewrk!~andrewrk@mail.ziglang.org
looks like "rvrb" is a different github account

1768335356
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
Oh so doing `for (data) |d| write(d)...` and then loop `for (0..splat-1) ..` would actually be wrong because the last item shouldn't be written at all if splat is 0?

1768335493
andrewrk!~andrewrk@mail.ziglang.org
that's correct, unfortunately

1768336141
andrewrk!~andrewrk@mail.ziglang.org
rvrb: I added a reply to the thread: https://ziggit.dev/t/resizable-structs-in-zig/11198/24?u=andrewrk

1768337872
rvrb!~rvrb@156.146.51.230
andrewrk: I got bored with it, basically, lol. kristoff had an alternate approach they worked on on stream, a few of us bike shedded different things. ultimately felt the 'obese pointer' was not worth it

1768337893
rvrb!~rvrb@156.146.51.230
I think it's gone but I had a version that was more flexible and could support arbitrary shapes with shared lengths and stuff 

1768337938
rvrb!~rvrb@156.146.51.230
maybe this? https://github.com/tristanpemble/zig-tail/blob/main/src/root.zig

1768338042
rvrb!~rvrb@156.146.51.230
looking at it, this approach modeled it more like a 'tail slice' - there's a head that is fixed size and a tail that is dynamically sized. lengths could be stored in both the head or tail and shared

1768338079
rvrb!~rvrb@156.146.51.230
the Tail is a zero sized struct that uses @fieldParentPtr

1768338128
rvrb!~rvrb@156.146.51.230
I think I was also exploring storing the length externally, no idea why

1768338146
rvrb!~rvrb@156.146.51.230
oh I think maybe that was to marry both the obsese slice external length storage with the internal length storage

1768338265
rvrb!~rvrb@156.146.51.230
see also https://github.com/kristoff-it/zig-flex

1768340926
rvrb!~rvrb@156.146.51.230
working on a simplified version with 6 months more experience with zig..

1768342371
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
How do for loops work with multi-dimensional arrays? If I iterate over the outer dimension of an array, will the inner rows get copied to the capture value on each iteration?

1768343982
andrewrk!~andrewrk@mail.ziglang.org
ii8: use |*foo| syntax

1768344352
cow_2001!~username@user/cow-2001/x-5712099
i don't know if anyone would do it the way i did, but this "inline for" gizmo is great :| http://0x0.st/s/jLEXvTwRF_8Clv-d54g-5Q/P8il.txt

1768346104
ii8!~ii8@2001:19f0:7400:144b:1670:baf9:f4b:4508
Ahh, tyty

1768346460
rvrb!~rvrb@156.146.51.230
andrewrk: how is this for your use cases https://codeberg.org/tristanpemble/zig-flexible-struct

1768346487
rvrb!~rvrb@156.146.51.230
not completely done but the fundamental is there.. need to handle auto layout field sorting 

1768346581
andrewrk!~andrewrk@mail.ziglang.org
how does the caller know to use 128?

1768346605
rvrb!~rvrb@156.146.51.230
I can make calcSize public

1768346612
rvrb!~rvrb@156.146.51.230
I just picked a random number

1768346612
andrewrk!~andrewrk@mail.ziglang.org
can it be called at compile time?

1768346614
rvrb!~rvrb@156.146.51.230
yeah

1768346627
andrewrk!~andrewrk@mail.ziglang.org
should work then

1768346637
rvrb!~rvrb@156.146.51.230
or, I can make one that is initStack or something that returns an array? I don't know how that API would work

1768346653
andrewrk!~andrewrk@mail.ziglang.org
oh that's neat how you did the length thing

1768346661
andrewrk!~andrewrk@mail.ziglang.org
that lets the user control the type as well

1768346701
andrewrk!~andrewrk@mail.ziglang.org
if you want to see my real world use case, it's in my poll branch of zig, impl in lib/std/Io/File/MultiReader.zig, usage in lib/std/Build/Step.zig

1768346728
rvrb!~rvrb@156.146.51.230
oh, you mean that the length type if configurable so you can do u8 or whatever

1768346730
rvrb!~rvrb@156.146.51.230
yeah

1768346783
andrewrk!~andrewrk@mail.ziglang.org
it doesn't compile yet sorry

1768346899
andrewrk!~andrewrk@mail.ziglang.org
I would love something like this in the std lib if you're willing to contribute it

1768346941
rvrb!~rvrb@156.146.51.230
yeah I am

1768346945
rvrb!~rvrb@156.146.51.230
where should I put it

1768347156
rvrb!~rvrb@156.146.51.230
feels like it just needs to be in like std.flexible_struct. idk, I'll just PR it and discuss there

