1573949922
adamkowalski
Snektron I really like that, however, there's something quite nice about the built in slices and arrays. That means it's easy to mix dimensions that are statically known and things that are known at runtime

1573949947
adamkowalski
And it would play nicer with the language, then immediately coming in and building in my own matrix or nd array type

1573949958
adamkowalski
It would be nice to have [][5][]int

1573949984
adamkowalski
I just think that the language should be consistent and if you can cast arrays to slices, you should be able to convert nd arrays to nd slices

1573950028
adamkowalski
And mix and match at will to encode by the type system which dimensions are known at runtime vs compile time

1573950047
adamkowalski
Then you can have something like a jagged array, where you have 5 rows, but each row has a variable amount of columns

1573950605
fengb
nd arrays don’t really exist. It’s basically the same as how C works with them

1573950898
Snektron
adamkowalski: you can already have the type [][5][]i32

1573950952
Snektron
I think the first thing youre going to have to ask yourself is: Do you want to have an ND array blas-like library

1573950960
Snektron
Or do you want 3D matrices

1573950960
fengb
An array of slices is almost definitely not what he wants though

1573950985
Snektron
Because its starting to sound like the latter and i doubt that construct even makes mathematical sense

1573951081
Snektron
fengb: no i think they want is slices and pointers to arrays of static size

1573951120
Snektron
The problem with that approach is, adamkowalski, that you then have to store an unknown amount of pointers in your dynamic matrix structure

1573951139
Snektron
Which binds your structure to the heap

1573951162
Snektron
I think its hard to make a structure which generalizes over both

1573951190
Snektron
So instead you could make a matrix storage type and generalize operationd over that

1573951199
fengb
Arrays are fixed memory blocks known by the compiler. Slices are pointers into those memory blocks. They translate well only at 1 dimension level

1573951299
Snektron
So what you'd have with the last approach is `fn Matrix(comptime T: type, comptime S: type) type { returnt struct { storage: S }; }`

1573951332
Snektron
Where S has a few getters and setters for elements as well as getters for the dimensions

1573951359
Snektron
In fact this approach is taken by libraries such as Eigen

1573951436
Snektron
Personally i dont really use dynamically sized matrices very often so i just dont bother

1573951456
Snektron
Anyway, the storage could be a number of things here:

1573951467
Snektron
- statically sized with array backing

1573951482
Snektron
- dynamically sized with heap backing

1573951528
Snektron
- different types of views of other matrices, either static or dynamically sized, with different types of pointers to other matrices

1573951600
Snektron
Those different pointer types could be something like pointers to dense matrices, a list of pointers to  individual memory locations, or a pointer/stride kind of system

1573951632
fengb
I’ve used a comptime 1D array/slice with a struct to set width/height:

1573951663
fengb
Probably my C experience speaking but it seemed to work a lot better than 2D arrays

1573951748
fengb
I also didn’t do math so not sure how well it applies to your usecase

1573951795
Snektron
Some example code which you can do is use `Matrix(MatrixView(0, 0, 2, 2, DenseSrorage(4,4))).init(MatrixView(0,0,2,2, DenseStorage(4,4)).init(&other).transpose()` to transpose only the upper 2 by 2 submatrix of a 4 by 4 matrix

1573951828
Snektron
But as you can see thats a lot of code and nasty types, something which might be better suited for a language like rust

1573951920
Snektron
fengb: should the width/hight of Matrix not be made comptime

1573951950
Snektron
Also note how you can abstract out storage types and then you'd basically what i was talking about

1573952281
fengb
Returning arrays requires something to be comptime known. I suppose the concrete type could be an oversized array

1573952299
fengb
Returning arrays on the stack*

1573952343
Snektron
Btw, there was an article about designing matrix libraries somewhere, might be relevant

1573952682
Snektron
Ah

1573952704
Snektron


1573952738
Snektron
Also some my own 3D math stuff:

1573952844
Snektron
Iirc its largely conformant to the article above, and i used some nice templates to do it

1573952859
scientes
Snektron, thanks for that link

1573952910
scientes
Snektron, SIMD is coming

1573952913
scientes
being merged

1573953030
Snektron
SIMD is another topic

1573953042
Snektron
On that, what do you mean by "its coming"

1573953055
scientes
Snektron, this is my PR

1573953063
scientes
I didn't fully rebase after the last merge

1573953069
scientes
but I will get around to it eventually

1573953079
Snektron
Does that mean @Vector will be hardware backed or does it mean turning on llvm simd optimization?

1573953085
scientes
it already is

1573953094
scientes
you just can only do limited things with it

1573953113
scientes
Snektron, vectorization is very difficult, it is much easier to devectorize

1573953130
scientes
that is the whole point of using these intrinsics

1573953134
scientes
and LLVM's SIMD features

1573953218
Snektron
So this is just @Vector stuff?

1573953239
Snektron
Also, note that using simd for 3D math is an anti pattern

1573953250
Snektron
Dont confuse the two

1573953295
scientes
Snektron, you want simd for ray tracing

1573953362
Snektron
Usually i rely on LLVM autovectorize for stuff like that

1573953379
Snektron
Its priddy gud

1573953401
Snektron
Though ray tracing i usually offload to a gpu

1573953419
scientes
AMD does their compilation with llvm

1573953422
scientes
it uses these features

1573953435
scientes
I met a top AMD LLVM engineer at the LLVM conference

1573953489
scientes
same with mali at ARM

1573953596
Snektron
But thats something completelt different from LLVM autovectorization

1573953640
Snektron
If you write code with intrinsics llvm will literally try to vectorize that

1573953712
Snektron
A friend was working on llvm for his bachelors thesis and was complaining how aggressively it kept trying to autovectorize stuff, even his additions (which where stuff like bounds checking for arrays)

1573953725
Snektron
(And some pointer stuff)

1573961764
daurnimator
Aransentin: what do you mean by "comptime-omit"?

1573961802
daurnimator
mq32: its the

1573961913
daurnimator
everything else I've come up with fails for some reason (usually inability to reference the type; or something about generic being unintrospectable)

1573962937
gruebite
anyone know why i would get wchar.h not found when building a shared library?

1573962943
gruebite
cImport failed

1573963108
daurnimator
gruebite: did you link against libc?

1573963191
gruebite
it's an include error

1573963210
gruebite
i have tried linking libc

1573963222
gruebite
i ended up adding c.addSystemIncludeDir("/usr/include")

1573963228
gruebite
paths might be messed up? env vars?

1573963256
daurnimator
gruebite: zig doesn't include your system include dirs by default

1573963280
gruebite
gotcha

1573963333
daurnimator
though I vaguely recall something like linking the system libc adds those include dirs

1573963339
daurnimator
but now I can't find that code path...

1573963476
daurnimator
hrm... reading the source of std/build, the only thing that sets `need_system_paths` is linkSystemLibraryName....

1573963517
daurnimator
but `linkSystemLibraryName` doesn't get hit from `linkSystemLibrary("c")`

1573964703
gruebite
hmm i coulda looked there

1573964705
gruebite
:D

1573964707
gruebite
thanks

1573964739
gruebite
now i'm getting an interesting issue. some symbols are not being generated. skipped a lot of the functions

1573964802
gruebite
everything else i got, just no functions. except for a couple

1573965146
gruebite
hopefully someone can see why:

1573965147
fengb
Is there a way to subtract two pointers?

1573965202
daurnimator
gruebite: run `zig translate-c` over your header to see what zig makes of it

1573965249
gruebite
ahh, nice

1573965259
daurnimator
fengb: no (aside from @ptrToInt):

1573965295
daurnimator
fengb: oh wait. > Note that you can subtract integers from (unknown length) pointers, and you can add integers to pointers. What does not work is adding pointers to pointers or subtracting pointers from pointers.

1573965328
fengb
nvm, i'm translating the C too literally >_>

1573965330
gruebite
daurnimator: yep, i did that and put the cimport.zig into the gist. the function symbols are completely gone, but everything else is there

1573965335
gruebite
silent error?

1573965342
fengb
Although it'd be nice to subtract 2 pointers and get the size diff

1573965358
daurnimator
gruebite: add --verbose-cimport

1573965425
gruebite
not sure that changed anything, same output

1573965449
gruebite
oh nvm

1573965585
gruebite


1573965589
gruebite
macroqualified errors

1573965660
gruebite
any suggestions?

1573965698
gruebite
i'm assuming it's the API macros which do dllexport stuff for windows. can these be ignored safely?

1573965783
daurnimator
gruebite: where is GDAPI defined?

1573965890
daurnimator
gruebite: seems to be:

1573965934
gruebite
yeah

1573965940
daurnimator
gruebite: perhaps zig just doesn't understand `__attribute__((sysv_abi))` ?

1573965950
gruebite
appears that way

1573965965
daurnimator
gruebite: are you able to edit your header file to see if it works if you define the calling convention to be empty?

1573966004
gruebite
yep

1573966007
gruebite
trying now

1573966085
gruebite
and it builds

1573966114
daurnimator
gruebite: cool :) so I guess you should file a feature request for zig to support `__attribute__((sysv_abi))`?

1573966235
gruebite
yarp, thanks. --verbose-cimport is helpful

1573966370
gruebite
can i override C defines in build.rs?

1573966385
daurnimator
.rs? you've overdosed on rust

1573966386
gruebite
like `lib.cUndef("X")`

1573966394
gruebite
:P

1573966397
gruebite
i may have

1573966400
gruebite
i use it at work

1573966483
daurnimator
gruebite: no you can't override defines. good C headers do things like #ifndef FOO\n#define FOO somedefault\N#endif

1573966582
gruebite
well, then my only option is to run a temporary patch over the header to build

1573966608
daurnimator
gruebite: yes; unfortunately. Hopefully you can get support for that

1573967649
gruebite
yeah

1573967659
gruebite
can i import more than one header into c?

1573967667
gruebite
or separate consts for each

1573967679
gruebite
could have my own header which imports all headers i need

1573967985
daurnimator
gruebite: you have same username on github?

1573968064
gruebite
yep

1573968084
daurnimator
gruebite: enjoy:

1573968219
gruebite
nice! thank you :D

1573969305
gruebite
just got this

1573969309
gruebite
that was quick!

1573969338
daurnimator
gruebite: do you want/need the .h header output for your library?

1573969395
gruebite
what do you mean?

1573969436
daurnimator
gruebite: when zig creates a library, it generates the .a/.so and a .h for it

1573969472
daurnimator
That TODO is coming from the .h file generation code: if you don't need the header file, add --disable-gen-h

1573969652
daurnimator
relevant issue:

1573969754
gruebite
ahh, yeah i just searched the issue and found that command.

1573969765
gruebite
is there a method on Builder to add that option?

1573969777
gruebite
just greping build.zig heh

1573969838
daurnimator
gruebite: yeah for now greping std/build.zig is the way to find out. seems like you want: .setDisableGenH

1573969883
adamkowalski
Thanks for all the information everyone. I really like the article about building matrix/vector libraries.

1573970035
adamkowalski
For my use case, I need ND array support, scalars, vectors, matrices, etc are all just special cases of the more general notion. Unfortunately, you don't know the size until runtime for a lot of problems where you won't know the dataset until runtime either. This means there will have to be a heap allocation. The dream is to have something which can handle both statically known and dynamically known

1573970041
adamkowalski
dimensions and can provide type safety where appropriate. Meaning if you know the dimensions at compile time and you try to multiply something that doens't make sense, then it should be a compile error. Otherwise you should be forced to `try` since the dimensions may not line up at runtime

1573970120
daurnimator
adamkowalski: re: static vs dynamic for same structure, I've got this in an open pull request right now:

1573970146
adamkowalski
I think the approach I will go with is to have a 1 dimensional array which is the backing memory, and then translate the nd cartesian index into the linear index. The type will be parameterized on the element type, and at runtime accept the dimension sizes as well as the strides.

1573970149
gruebite
daurnimator: woo, got it working and calling from godot

1573970152
gruebite
thanks

1573970162
daurnimator
adamkowalski: you could easily follow the same pattern I did in the commit in a vector/matrix library

1573970187
adamkowalski
If you all are also working on linear algebra libraries we should consolidate our efforts

1573970210
daurnimator
adamkowalski: I am not; that is a buffer structure mainly to be used for network/file operations

1573970228
daurnimator
adamkowalski: sometimes you know the size of what you're going to receive; other times its unbounded => so similar sort of thing to what you're talking about

1573970241
daurnimator
However I'm not looking at linear algebra stuff at all (nor is it on my personal roadmap)

1573970255
adamkowalski
I'm baised towards machine learning, but I know they are also commonly used for game development. I'm not sure how much things will overlap, but it would be nice to have one set of abstractions everyone can agree upon

1573970270
daurnimator
gruebite: hopefully the teething troubles weren't too much for you; if you ever hit something just file an issue; we're usually pretty quick about things that block people's progres.

1573970319
gruebite
:D

1573970320
adamkowalski
Is there a data science community within zig? I'm also starting to work on a plotting package, and would also want something like a data frame

1573970355
daurnimator
adamkowalski: not really. we're all in this together at this point :P

1573970367
adamkowalski
We currently still use Python at work, but I really want to evaluate using Zig since some of our simulations are starting to take extremely long

1573970389
adamkowalski
The only thing Python has going for it is all the libraries, but then all tend to break down at scale

1573970400
adamkowalski
I also love that Zig takes reliability and error handling so seriously

1573970413
daurnimator
adamkowalski: I would think zig is going to be too immature for anything not a once-off right now

1573970433
adamkowalski
Perhaps, but it's got a lot of things going for it

1573970449
adamkowalski
The alternatives we've looked at are C++ , D, Rust, and Julia

1573970449
daurnimator
indeed; and it'll only get better if people keep using it and keep contributing things

1573970478
adamkowalski
Julia has a really great ecosystem, and is something I want to steal many ideas from. However, it uses a jit and so the startup times are unacceptable

1573970491
adamkowalski
The one thing they do that i'm not sure how to mimic here is automatic differentiation

1573970504
adamkowalski
They actually provide hooks into the compiler so that you can record every operation that is happening

1573970523
adamkowalski
Then they can play them back in reverse and use the chain rule to give you the derivatives

1573970539
adamkowalski
Which is the main thing you need in order to solve an optimization problem

1573970570
adamkowalski
When you want to approximate integrals they also use monte carlo

1573970584
adamkowalski
But if we had those two things solved, I think zig could be a strong contender

1573970639
daurnimator
adamkowalski: interesting. I'm curious what andrewrk would say about getting automatic differentiation

1573970679
adamkowalski
hopefully it can happen as a library, since that would show off how flexible the language is

1573970684
daurnimator
adamkowalski: for clang they have things like clad... I don't know if that sort of approach is worthwhile for zig

1573970700
adamkowalski
But if we want it to be a part of the language, we can look at swift for tensorflow

1573970713
daurnimator
adamkowalski: I'm wondering if it violates one of the tenants of zig: "no hidden control flow" => automatic differentiation sounds like hidden control flow to me

1573970738
adamkowalski
They actually build a static computation graph and then you differentiate it, and can automatically distribute it across your cluster

1573970747
adamkowalski
daurnimator there is no hidden control flow

1573970764
adamkowalski
You still need to call loss.backward() in libraries like PyTorch

1573970778
adamkowalski
Or you call gradient(f, with_respect_to=parameters) in Julia

1573970788
adamkowalski
It's similar to defer in my opinion

1573970834
adamkowalski
Within the nd array type itself you simply have a "tape" (really it's just a stack)

1573970839
adamkowalski
then if you call add(x, y)

1573970848
adamkowalski
you record the "add" onto the stack

1573970867
adamkowalski
but you need to specify that you wish to track that particular array so you don't pay for what you don't use

1573970870
daurnimator
adamkowalski: where is the stack? where does its memory come from?...

1573970881
adamkowalski
in zig it would make sense to pass in an allocator

1573970937
adamkowalski
Are you all familiar with how a neural network works?

1573970948
adamkowalski
if I gave a really simple example it might make the workflow more clear

1573971076
adamkowalski
Lets say you want to predict the price of a house given a "feature vector" (the square footage, number of bedrooms, number of bathrooms, etc)

1573971089
adamkowalski
You each of these numbers into a vector x

1573971103
adamkowalski
now you have a matrix m and a vector b which is the same length as x

1573971111
adamkowalski
y = mx + b

1573971115
adamkowalski
y is your prediction

1573971127
adamkowalski
now you take the difference between your prediction and the true house price

1573971144
adamkowalski
so mean(absolute(y_true - y_pred))

1573971154
adamkowalski
mean because y_true and y_pred are vectors

1573971174
adamkowalski
abs because if the true house price is 400k it's just as bad to predict 350k and 450k

1573971191
adamkowalski
so loss = mean(abs(y_true - y_pred))

1573971200
adamkowalski
you want to take the derivative of loss with respect to m and b

1573971205
adamkowalski
since those are the parameters of your "model"

1573971236
adamkowalski
this gives you a vector of "partial derivatives" or your "gradient vector"

1573971246
adamkowalski
this tells you how to adjust each parameter such as to minimize your loss

1573971257
daurnimator
I guess you'd want to specify the numeric type of your derivitives?

1573971259
adamkowalski
If your loss is 0, your prediction matches the true value

1573971272
adamkowalski
yeah usually those are f16

1573971277
adamkowalski
or even quantized i8

1573971283
daurnimator
==> if you have a function that mixes doubles and u16s.... you end up on f16 how?

1573971288
adamkowalski
you take your floats and chop of as much precision as possible

1573971305
adamkowalski
well f16 or i8 is best because the GPU can churn through that

1573971318
adamkowalski
and it turns out the lower precision actually helps your model generalize

1573971318
daurnimator
I guess with zig you could do: df = gradientf(f, f16); df(some, args);

1573971339
adamkowalski
that would be the dream

1573971343
adamkowalski
a one function api

1573971347
adamkowalski
which is a higher order function

1573971350
adamkowalski
it would take a function

1573971359
adamkowalski
and return a function which gives the deriviate

1573971372
daurnimator
how do you deal with functions that have side effects?

1573971382
daurnimator
e.g. what the derivitive of the write() syscall?

1573971392
adamkowalski
I would recommend a functional style

1573971399
adamkowalski
However, there is nothing wrong with side effects

1573971414
adamkowalski
for example in reinforcement learning you have an agent which interacts with the environment

1573971418
adamkowalski
you can still take the derivative

1573971419
daurnimator
when calculating the derivitive, you still perform all the operations?

1573971431
adamkowalski
well you only do the forward pass once

1573971438
adamkowalski
you just record which operations were performed

1573971454
daurnimator
How would you only do the forward path once if not all branches are taken?

1573971469
adamkowalski
you're asking all the right questions

1573971480
adamkowalski
that was a problem back in the day with tensorflow 1.0 and static graphs

1573971490
adamkowalski
you had to define your entire model as a static computation graph

1573971500
adamkowalski
it had to be pure with no side effects and no control flow

1573971507
adamkowalski
they then introduced control flow nodes

1573971511
adamkowalski
called if_ and while_

1573971522
adamkowalski
which took lambdas for the the condition and for the body

1573971531
adamkowalski
so you only call the labmda for the branch that was taken

1573971544
adamkowalski
then the derivative would be the deriviative of the chosen branch

1573971566
adamkowalski
now people do whats called dynamic graphs in tensorflow 2.0, pytorch or flux

1573971585
adamkowalski
so you just write down regular looking code like y = m * x + b

1573971601
adamkowalski
and it will automatically generate the graph behind the scenes and figure out the derivatives

1573971631
adamkowalski
However, you then pay a performance price since you don't know what ops are going to be taken and which control flow branches you will go down

1573971650
adamkowalski
But as long as you are dealing with big enough arrays it tends to not be the dominating factor

1573971655
daurnimator
`y = m*x + b; if (y > 5) { y += somesyscall(); } else { y << 10 }` ==> how do you get the derivitive of this?

1573971686
adamkowalski
okay so assume that you are tracking m and b

1573971692
adamkowalski
you do m * x

1573971696
adamkowalski
record * on the tape

1573971708
adamkowalski
then you add b so you record +

1573971717
adamkowalski
now assuming we are talking about the dynamic graph frameworks

1573971722
adamkowalski
you literaly run the control flow

1573971728
adamkowalski
and y is now a tracked array

1573971742
adamkowalski
since a tracked array + another array is still tracked

1573971749
adamkowalski
it just records the operations

1573971760
adamkowalski
so it all just works

1573971766
adamkowalski
you just record only for the branch you went down

1573971784
adamkowalski
the operations themselves are the things responsible for writing down to the tape

1573971791
adamkowalski
The only thing you can't do that you listed here is y +=

1573971795
adamkowalski
you can't modify in place

1573971808
adamkowalski
unless the semantics of your language is that y += blah -> y = y + blah

1573971815
adamkowalski
now you are creating a new variable and all is good

1573971817
daurnimator
I'm not sure I understand. Perhaps you could write out the above sample with the contents of the tracking vector at each point?

1573971839
adamkowalski
theres a really good visualization, let me find it

1573972033
adamkowalski
I can't find it yet but look at this if you want to see flux docs

1573972036
adamkowalski
they are great

1573972046
adamkowalski
It shows the actual code you write

1573972052
adamkowalski
and it shows off the one function API

1573972070
adamkowalski
it will get you from i've never written a neural network, to I can do image recognition in maybe 30 minutes

1573972075
adamkowalski


1573972078
adamkowalski
thats also great

1573972116
daurnimator
adamkowalski: I don't see any side-effect functions in that doc; which is what I'm struggling to understand

1573972129
daurnimator
adamkowalski: also would appreciate knowing where the storage comes from for tracking

1573972131
adamkowalski
Heres mxnet

1573972143
adamkowalski
The storage comes from the parameters themselves

1573972156
adamkowalski
the nd array has allocated the data for the array as well as the tape

1573972165
adamkowalski
well it depends on the library

1573972177
adamkowalski
flux has a tracker type which wraps an array type

1573972184
adamkowalski
then the array is agnostic to auto diff

1573972188
adamkowalski
since you might just use it for math

1573972192
daurnimator
adamkowalski: could you write up a hypothetical for how it would work in zig? with contents of tracking vars?

1573972208
daurnimator
adamkowalski: you could do it in an issue/proposal if you want. gives a place for discussion to congregate on the issue

1573972215
adamkowalski
yeah i'll have to work on it for a while

1573972222
adamkowalski
I'll try and build a proof of concept

1573972228
adamkowalski
first step is building out the nd array

1573972239
adamkowalski
once we get that working we can move on to tracking

1573972249
adamkowalski
I can get in touch with the authors of those libraries too

1573972261
adamkowalski
they are really friendly and much smarter then I haha

1573972304
adamkowalski
about side effects it just ends up not mattering

1573972315
adamkowalski
as long as the result of the side effect gives you a flow

1573972317
adamkowalski
float*

1573972325
adamkowalski
and you add it to your current tracked variable

1573972328
daurnimator
I don't understand how that can be the case

1573972332
adamkowalski
then the add op will just get registerd

1573972424
adamkowalski
I found the visualiztion!!

1573972440
adamkowalski
Scroll down to the graph is created on the fly

1573972509
adamkowalski
Also keep in mind you can't just take derivatives of anything, it has to be of things that operate on nd arrays

1573972523
adamkowalski
Pretty much only things that are part of the pytorch library

1573972542
adamkowalski
but if you generate an ndarray from some other source, then turn it into a pytorch ndarray things will still work

1573979752
tdeo
is there something in the standard library to turn null-terminated strings into slices? there was an issue that mentioned the cstr module but i don't see anything in there

1573980100
tdeo
wrote my own simple one, would the three lines be welcomed in the standard library? :)

1573980376
dbandstra
i think std.mem.toSlice and std.mem.toSliceConst do that

1573980486
dbandstra


1573980514
tdeo
ah, thanks

1573980524
tdeo
weird that it doesn't mention anything about null termination

1573982650
hooo
this is messed up naming: std.heap.direct_allocator vs. net.IpAddress or std.AutoHashMap

1573982663
hooo
either camel case or no right

1573982693
tdeo
direct_allocator isn't a type

1573982697
tdeo
it's a global

1573982746
hooo
I think 'const' should be removed from the language

1573982972
dbandstra
why should it be removed?

1573982986
hooo
it's compiler metadata, as a reader I dont care and as a writer I barely care that things are const.

1573983052
tdeo
i think const is very useful for communicating intent

1573983117
hooo
I think it's very confusing actually. If you make something const, what does it mean? I have no idea, now I have to assume that you had very good reason to make it const. But in reality that isnt the case, people make stuff const "just to be safe" with no thought

1573983185
dbandstra
i think you should make a variable const unless you have a reason not to

1573983445
hooo
so in other words, a zero thought decision that basically means nothing

1573983463
hooo
yet I have to read "const" all over the place and it confuses me and I have to assume that I cant just change it to var

1573983669
tdeo
is `field: []const u8 = [_]u8{}` the best way to have an empty default for strings? (unrelated to above)

1573983727
dbandstra
i don't see how const could possibly be confusing... out of all the things in zig it's one of the more straightforward things

1573983767
dbandstra
i do find it helpful when reading code, helps me narrow down more quickly what's going on in a function when i can see at a glance that a certain variable won't be mutated

1573983783
dbandstra
tdeo: `""` is the same thing

1573983805
tdeo
aha, thanks

1573983817
tdeo
don't know why i didn't realize that

1573987003
mq32
heyhoh

1573987030
mq32
there isn't an online archive of older zig versions dailies, right?

1573988345
mq32
error: expected type 'block-iterator.enum:3:28', found 'block-iterator.enum:3:28'

1573988356
mq32
okay, this is the most ... weird bug i've seen yet :D

1573989217
mq32
okay wtf

1573989221
mq32
this is obscure

1573989836
daurnimator
hooo: const should be the default choice; you make something variable only if you intend to modify it

1573990135
mq32
does someone here already use github actions?

1573990785
daurnimator
mq32: sorry; nope

1573990795
daurnimator
mq32: did you have any further thoughts about my callback thing?

1573990804
mq32
no, sorry

1573990822
mq32
your solution is kinda ... interesting, but i cannot tell how good that would work out in a real environment

1573990827
mq32
i'm playing around with Github Actions right now

1573990837
mq32
builing my retros project with that

1573990858
mq32
i should inform myself how those "modules" work

1573990865
daurnimator
oh my solution is super unergonomic. but I can't find anything else that even works

1573990875
mq32
because then we could have a zig provider for github CI

1573990878
daurnimator
nor can my solution be made prettier with helpers

1573990886
mq32
=> everybody could CI the zig projects :)

1574001074
daurnimator
TIL about gcc's closures...

1574001455
mq32
daurnimator, yeah that's the biggest drawback of this closure style

1574001469
daurnimator
mq32: not really; it's just how they implemented them

1574001481
mq32
yeah

1574001491
daurnimator
for zig we can actually change the function signature of the inner function to inject a hidden "pointers to upvalues" parameter

1574001496
mq32
a separate thread_local closure stack would probably sort this out

1574001515
daurnimator
otherwise you can do it by e.g. mapping separate executable area and loading it in; instead of sharing it with your stack

1574001574
daurnimator
(essentially acting as your own runtime dynamic linker)

1574001578
mq32
daurnimator "pointer to upvalues" would be a "fat" function pointer?

1574001798
daurnimator
mq32: e.g. `const adder = fn (x: usize) var { return fn (y: usize) usize { return x+y; } }; const increment = adder(1);` => `increment` gets compiled to a function that you could write like: `fn increment(upvalues: struct { x:

1574001862
mq32
ah

1574001870
mq32
yeah, that side is clear to me

1574001883
mq32
the question is: how does the other side work?

1574001889
daurnimator
"other side"?

1574001919
mq32
passing that function pointer to "somewhere"

1574001938
mq32
because hiding the parameter is one thing

1574001938
daurnimator
mq32: if we're in pure zig land we don't really have function pointers.

1574001959
mq32
passing the upvalues as an argument is another thing

1574002155
daurnimator
The real tricky bits are if upvalues are captured by value or by referencce.....

1574002218
mq32
i really like the C++-Approach here

1574002221
mq32
it's quite transparent

1574005918
mq32
error of the day:

1574005926
mq32
error.ExpectedValueWasNotTwo

1574008531
companion_cube
I like the rust approach: all captures by ref, or all by move

1574008897
Snektron
Isnt that annoying

1574009182
companion_cube
it's more about whether the closure is its own thing, or just a wrapper around existing references

1574012693
adamkowalski
If I have a static array thats being passed as an argument to the function, is there a way to say that it's length must be the same as the other argument?

1574012727
adamkowalski
Currenlty I'm passing a comptime unsigned int and the type of both of the arguments followed by the arguments themselves

1574012754
adamkowalski
I'm used to templates where those things would get infered rather then having to explictly type them

1574012763
mq32
fn(comptime L : comptime_int, a: [L]u8, b: [L]u8) void;

1574012764
adamkowalski
template <type N, size_t L>

1574012781
adamkowalski
mq32 right but then I have to pass in the length as the first parameter right?

1574012792
adamkowalski
shouldn't it just know what L is and constrain a and b to be the same

1574012795
mq32
ye

1574012805
mq32
*yes

1574012835
adamkowalski
std::array<N, L> (const std::array<N, L> &x, const std::array<N, L>&y)

1574012837
mq32
zig does very little implicit stuff like that

1574012866
adamkowalski
so if I have nested static arrays for mat mul thats generic over element type and size I would need to write

1574012887
Snektron
Id probably take a var type

1574012910
Snektron
And static assert the size is MxN and NxO

1574012937
Snektron
Im not a fan of having to manually specify the type of generic functions

1574012960
adamkowalski
fn matmul(comptime T: type, comptime M: comptime_int, comptime N: comptime_int, comptime P: comptime_int, x: [M][N]T, y: [N][P]T) [M][P]T

1574012963
adamkowalski
that looks gnarly haha

1574012987
adamkowalski
so with var is there a way to constrain what it can take in? like a concept or a type class?

1574012999
mq32
adamkowalski: yes

1574013003
mq32
any comptime code

1574013027
adamkowalski
okay and since concepts are compile time predicates

1574013038
adamkowalski
you can just write a function which checks if you are a matrix at compile time?

1574013052
adamkowalski
is there docs on what you can learn about a type at compile time?

1574013082
Snektron
Yeah its in the language docs

1574013085
Snektron
But you shouldnt use that

1574013126
adamkowalski
i'm open to learning new things. how would you appraoch it then?

1574013141
mq32
first thing you can do is that:

1574013155
mq32
fn(a: var, b: @typeOf(a)) void

1574013160
Snektron
I think you could just do an assert on the width and height

1574013161
mq32
that would enforce the same type

1574013170
mq32
and then you could

1574013178
Snektron
Types of matmul arent the same

1574013180
Snektron
You could do

1574013235
Snektron
fn matmul(a: var, b: var) ... { assert(a.width() == b.height(); ... }

1574013258
Snektron
Still need to calculate the return type though

1574013283
Snektron
The assert will run at compiletime

1574013296
Snektron
So you could also make width and height static fields

1574013352
Snektron
Maybe it would be beneficial for Zig to have something like concepts

1574013372
mq32
Snektron: there was a proposal for that already

1574013376
Snektron
Well, they would be more like how contracts in lisp work

1574013403
Snektron
It would predicate on parameters really

1574013410
Snektron
Oh? Do you know the issue?

1574013468
Snektron
Im not sure if it would be any more useful than static asserts since theres no overloading anyway

1574013479
Snektron
Maybe to just provide better intent/documentation

1574013511
fengb
It’d be better documented in the func signature

1574013514
adamkowalski
Yeah if everything is a var it seems like it's hard to document the possible inputs to your function

1574013525
adamkowalski
concepts/typeclasses/traits/protocols/ whatever would be nice

1574013547
mq32


1574013551
adamkowalski
I see that the allocators are passed by pointers

1574013567
adamkowalski
but why are we using runtime polymorphim instead of static dispatch

1574013625
Snektron
Less annoying to program

1574013628
adamkowalski
is passing by var kindof equivalent to passing by template?

1574013642
adamkowalski
so you can pass by const ref of a templated type

1574013647
Snektron
Allocating is a large overhead anyway

1574013650
Snektron
Its not like that virtual call is gonna cost you

1574013661
adamkowalski
and then as long as the compile time interface is satisfied you can pass in the param

1574013680
adamkowalski
Well I guess, but I'm not sure what the advantage of the virtual call is?

1574013704
Snektron
Not having to make everything that uses an allocator generic

1574013706
adamkowalski
And if zig is aiming for the zero overhead principl I feel like we should reserve runtime polymorphism for when you only know the type at runtime

1574013734
adamkowalski
Hmm, is there something wrong with being generic?

1574013742
adamkowalski
I try to make everything generic most of the time

1574013755
adamkowalski
It makes it easy to unit test, because you can pass in anything that meets the interface

1574013769
adamkowalski
So if I want to not actually connect to a database, but just have a mock object

1574013772
adamkowalski
then that all just works

1574013785
fengb
andrewrk’s goal is to have an “interface” that can seamlessly switch between comptime and runtime dispatch

1574013796
adamkowalski
or if you want to not actually do file IO, or you want to simulate memory allocation failure

1574013808
mq32
adamkowalski: it makes your binary larger and your code harder to debug

1574013809
adamkowalski
fengb that would be cool, but how would that work?

1574013825
adamkowalski
rust does that with traits and they have dyn traits for runtime polymorphism

1574013855
adamkowalski
mq32 it's a tradeoff between potentially having instruction cache misses versus the cost of a virtual dispatch

1574013869
adamkowalski
in general it seems the consensus seems to be that anythign dynamic/runtime is slower

1574013871
mq32
adamkowalski: if "code size" doesn't matter to you, yes

1574013888
mq32
if you are in a heavily restrained environment, it gets much more important to be small than "nice"

1574013889
adamkowalski
code size only blows up if you specialize for a bunch of different types

1574013911
adamkowalski
for me performance matters more (as in throughput) then code size

1574013934
adamkowalski
for safety critical machine learning systems you want to allocate all the memory you're going to use up front

1574013942
mq32
:D

1574013953
adamkowalski
then you build a model which you know will run in a fixed memory/time complexity

1574013966
mq32
i don't have space for "allocating" in half of my projects anyways :D

1574013967
adamkowalski
and you can reuse the same memory over and over again

1574013985
fengb
We haven’t found a solution yet, but comptime is still a newish concept so there’s a few potential ideas

1574013988
adamkowalski
well it seems like that is more niche then the case for optimizing for performance

1574013998
adamkowalski
I feel like we have release safe and release fast

1574014014
adamkowalski
but also having a way to explicitly decide if you want static or runtime polymorphism means you can choose

1574014029
adamkowalski
if everyone is forced into virtual dispatch because some people prefer code size

1574014036
adamkowalski
that doesn't seem like a good choice either

1574014049
adamkowalski
we should have a mechanism of choice like in c++/d/rust/julia

1574014071
mq32
yeah i'm with you there ;)

1574014080
mq32
i just have the problem right now that i cannot even use release-safe :D

1574014086
mq32
executable is too big

1574014121
adamkowalski
which is something that is great to support as well. however, there is a cost to doing dynamic dispatch

1574014131
adamkowalski
when doing numeric code I tend to have nd arrays of floats haha

1574014137
adamkowalski
so specialization doesn't harm me

1574014137
Snektron
I thought julia was pretty interesting but its sad they adopted 1-indexing

1574014151
adamkowalski
Eh thats a non issue, you stop thinking about that after day 1

1574014162
adamkowalski
they followed the Fortran style of column major + 1 based indexing

1574014169
adamkowalski
but they also have arbitrary indexing

1574014179
adamkowalski
you can choose an start index that makes sense for your domain

1574014191
adamkowalski
under the hood it gets inlined and turned back into the one based indexing

1574014208
adamkowalski
it's a great language for machine learning, maybe better then Python since it's producing really fast code

1574014230
adamkowalski
but your startup time is in the minutes if you include any libraries since it doesn't cache the compilation artifacts

1574014237
adamkowalski
so you can't ship your product to end users

1574014245
adamkowalski
thats actually the language I'm migrating from haha

1574014526
adamkowalski
Snektron did you see the visualization I posted last night?

1574014534
adamkowalski
Did that help with the side effect question?

1574014536
fengb
Embedded is a big target of zig so I don't think small size would be "just a niche"

1574014624
adamkowalski
My point was that we should make these choices explicit right? Just like we have no hidden control flow or allocation

1574014632
adamkowalski
why would static vs runtime polymorphism be impliicit

1574015416
fengb
Is godbolt buggy? I can't seem to get it to output anything useful

1574015431
Snektron
fengb: yea

1574015450
Snektron
adamkowalski: i didnt see

1574017419
muffindrake
The @"this is a function name" syntax can be used without restriction on all zig functions, no?

1574018099
mq32
muffindrake: in theory, yes

1574018377
jessemeyer
o/

1574018408
jessemeyer
As per the docs: '// The stdcallcc specifier changes the calling convention of the function.'  What does the calling convention change to?

1574018439
jessemeyer
I'm making a WinMain application, and I want to ensure the __stdcall convention is satisfied.

1574018482
mq32
it changes it to stdcall

1574018483
jessemeyer
But the only example I see is to just export the function.  How does the linker know the convention to use?

1574018627
jessemeyer
I was hoping so.  Cheers!

1574018669
jessemeyer
Exporting takes care of that too?

1574018699
jessemeyer
I do not seem able to specify the calling convention of an exported function.

1574018759
mq32
jessemeyer: the linker doesn't care for calling conventions

1574018868
jessemeyer
mq32 Sure, but the compiler does, right?

1574018883
mq32
jessemeyer: yes

1574018939
mq32
this exports a stdcall function:

1574018977
mq32
jessemeyer: just look at this link ;)

1574019094
jessemeyer
When I export WinMain, I get the error : root source file has no member called main.

1574019112
jessemeyer
Sorry

1574019116
jessemeyer
I can export main just fine

1574019123
jessemeyer
But when I export it via stdcallcc I get that error.

1574019140
jessemeyer
export fn WinMain(hInstance: HINSTANCE, hPrevInstace: HINSTANCE, lpCmdLine: PWSTR, nCmdShow: INT) INT {    return 0;}

1574019142
mq32
also: zig exports WinMain on windows already. just have a pub fn main() void { } in your root file :)

1574019144
jessemeyer
That produces the code.

1574019183
jessemeyer
Thanks! So why doesn't Zig complain if I don't provide the calling convention?

1574019439
jessemeyer
I'm curious if it's a spurious error I should report on the forums.

1574019477
jessemeyer
I mean Github.

1574019499
mq32
because nobody doens't care for bad calling conventions in the wild world

1574019515
mq32
you could also export WinMain as an i32 and the linker and compiler would be happy to eat that

1574019526
mq32
and then windows wants to call your i32 and your program will explode

1574019584
jessemeyer
I understand that conventions have to be upheld by shared parties.  I don't understand how that's connected to Zig's main() missing error.  Seems totally unrelated.

1574019710
mq32
zig expects you to either have a pub fn main() or a pub nakedcc _start()

1574019710
mq32
there are no other entry points allowed afaik

1574019770
jessemeyer
Makes sense. So it should warn about the lack of an entry point for this code (but it does not):

1574019783
jessemeyer
usingnamespace @import("std").os.windows;export fn WinMain(hInstance: HINSTANCE, hPrevInstace: HINSTANCE, lpCmdLine: PWSTR, nCmdShow: INT) INT {    return 0;}

1574019830
jessemeyer
It's built in build-exe mode.

1574021113
jessemeyer
When I specify stdcalcc to WinMain, it never gets called.  It does when I do.

1574024092
jessemeyer


1574024151
jessemeyer
What would cause lpCmdLine and hInstance to share the same reported address?

1574024155
jessemeyer
That looks like a compiler bug, no?

1574032997
cota
hi, I'm having trouble writing my first ever Zig program -- I'm generating a dynamic library to interact with C code. The library should export a function "foo_func" to get callbacks from C code, e.g. "void foo_func(struct opaque *cookie);", where struct opaque is only declared (not defined) in the imported C header file. I'm getting "error: C pointers cannot point opaque types" when building the library; is

1574033003
cota
there a way around this, e.g. defining the struct in zig to some dummy content?

1574034521
adamkowalski
I made my first pass at a matmul for arrays. Would you all say this is idiomatic zig?

1574034539
adamkowalski
What can I change or improve to make things more in line with the ways of the language

1574034653
adamkowalski
Also how do you compare values for equality? == is not overloadable, and std.mem.eql seems like it only works for 1 d arrays

1574034769
adamkowalski
Sorry for all the questions haha but I have one more. How do you debug test cases? Can I spit out a binary for those and attach lldb to em?

