1577059910
daurnimator
leeward: `try a()`

1577059931
daurnimator
* `a() catch |e| return e`

1577060122
daurnimator


1577060831
fengb
Are all BSDs supposed to use libc as the syscall layer?

1577060884
daurnimator
fengb: yes. except for when they don't :)

1577060916
daurnimator
if zig truely has the aim of "replace C" then at some point openbsd's loader/libc would need to be written in zig :P

1577061013
cshenton_
What's the go to way to debug print from a test block?

1577061044
adamkowalski
how do I get the scalar type of a multi dimensional array? and it's rank?

1577061061
adamkowalski
so if I have a [_]f64{1, 2, 3} I would want f64 and 0

1577061114
adamkowalski
[_][3]f64{

1577061114
adamkowalski
.{ 1, 2, 3 },

1577061115
adamkowalski
.{ 1, 2, 3 },

1577061115
adamkowalski
};

1577061118
adamkowalski
should be f64 and 2

1577061130
adamkowalski
the first example should have been f64 and 1 sorry

1577061175
cshenton_
You could do it with @typeInfo(@typeOf(ar)) then recursively check the container type, terminating when it's no longer an array.

1577061201
mikdusan
sounds like a good candidate for std.meta enhancement

1577061240
cshenton_
Lemme write up something real quick

1577062234
leeward
daurnimator: I know, I was talking about fengb's proposal, which would change that.

1577062364
cshenton
adamkowalski: here you go mate

1577062482
cshenton
Are you guys open to contributions to std.meta? Or are things a bit too unstable at the moment?

1577066497
adamkowalski
cshenton: awesome thanks!

1577066522
adamkowalski
do you know how to handle the case where you get a slice instead? I noticed the type info says it's a pointer and the child was a void

1577066698
daurnimator
cshenton: we're happy for contributions anywhere :P

1577066701
cshenton
Ah so that's where slices are. So the Pointer field of the TypeInfo enum has a field size that records the pointer type, so I can ad that case in.

1577066749
pixelherodev
z

1577066759
pixelherodev
Whoops - sorry about that!

1577066770
adamkowalski
cshenton: yeah I think we went down the same path. I started out with something that looked like what you had since I took inspiration from how expectEqual was implemented, but I coudln't figure out how to match on slices

1577066795
daurnimator
pixelherodev: z is for zig?

1577066816
cshenton
Matching on slices isn't to bad, you just add .Pointer to the switch statement and check the contents in the block. Let me slap that together and if it looks good I'll PR it.

1577066861
adamkowalski
Well before you do that, we should talk about eltype

1577066875
adamkowalski
i'm a little concerned that for array the child is called type

1577066878
adamkowalski
for pointer it's called child

1577066883
adamkowalski
and now we are introducing eltype

1577066897
adamkowalski
I think we should keep consistency if possible

1577066941
cshenton
I think that's reasonable.

1577066966
cshenton
eltype is just what julia uses in its stdlib, so I defaulted to it, consistency is more important

1577066977
adamkowalski
ah you are a julia user too?

1577066986
adamkowalski
awesome, I could use your help on a project i'm working on

1577067010
cshenton
Also would you consider [*]T a valid container type? Or just arrays and slices?

1577067013
adamkowalski
i'm building out a reverse mode automatic differntiation package

1577067031
adamkowalski
have you used TensorFlow, PyTorch, or Flux

1577067038
cshenton
Yup, used all of them

1577067072
adamkowalski
Awesome, I'm currently implementing a library called compute graph, so it's similar to tensorflow v1 and it's a static graph approach

1577067096
adamkowalski
I figured that way we can get distribution and parallization by analyzing the graph

1577067118
cshenton
Ah nice, you should also check out cpp-taskflow for inspiration.

1577067128
adamkowalski
i'm still working out exactly how to make everything work, but can you take a look at this test case and see what you think of the API so far?

1577067130
cshenton
The internals are much more readable than tensorflow

1577067139
cshenton
Yeah happy to take a look

1577067141
adamkowalski


1577067168
adamkowalski
I may have blatently stole the names from tensorflow, but hopefully it makes reading the code easier

1577067197
adamkowalski
I'm currently working on expanding from just working on scalars to working on tensors, hence the question I had earlier haha

1577067287
cshenton
This is a good start but I can think of ways of improving it. If each op returned both an op-id and a reference to the graph, you could chain operators:

1577067324
cshenton
like graph.mul(a, b).add(c); or something

1577067504
cshenton
Or you could have that classic split and offer both like `c = Constant(&graph, 2.0)` or `c = graph.add_constant(2.0)`

1577067644
cshenton
A lot of this is a matter of taste though.

1577067646
adamkowalski
the reason why I dind't want to make the methods be on the graph itself is because then there will be some number of "blessed functions"

1577067657
adamkowalski
you can't add new methods of your own that would be callable like that

1577067662
cshenton
Yep, that's a good point.

1577067664
adamkowalski
so I figured the consistency would be nice

1577067672
adamkowalski
unless we have ufcs

1577067689
cshenton
I was under the impression that wasn't likely to happen.

1577067713
adamkowalski
for constant I was going to use the ArrayInfo based on the var thats passed in and I will automatically construct the appropriate tensor

1577067734
cshenton
Nice

1577067750
adamkowalski
Since I don't have something like numpy or julias native array type, I also need to build a eager tensor which is the thing that will actually get passed into your operations

1577067786
adamkowalski
I'm not sure if there is anything I can do about that virtual call I have for the operation while maintaining the ability for users of the library to add custom operaitons

1577067792
adamkowalski
if you have any ideas i'm all ears

1577067847
cshenton
So tensorflow handles user-defined c++ ops with some macro magic, and python ops (which are more subgraphs) with inheritance.

1577067868
cshenton


1577067906
adamkowalski
It's still using inheritence

1577067907
adamkowalski
class ZeroOutOp : public OpKernel

1577067949
cshenton
Ah yeah, good point.

1577067962
adamkowalski
But all the actual eager tensor ops will be done using static compile time polymorphism and only the graph needs to be runtime polymorphic

1577067974
adamkowalski
at first I tried giving the graph itself an element type to get away from that

1577067998
adamkowalski
but you need to be able to injest different kind of data

1577068016
adamkowalski
so now i'm going to use a union(enum) over all the different primitive types that the cpu offers

1577068036
adamkowalski
that way you can have strings and one hot encode them to turn them into vector space representations and use word embeddings

1577068053
adamkowalski
but the thing I could really use help with is implementing the backprop

1577068079
cshenton
Yeah managing the allocations for that will be a bit awkward.

1577068087
adamkowalski
I was going to have a backward method on each operation which will be responsible for managing that

1577068095
adamkowalski
and you can chain ops that have backward defiend

1577068105
adamkowalski
the allocations are all in the arena that the graph uses

1577068120
adamkowalski
then when you're done with the graph you deallocate the whole arena at once

1577068140
adamkowalski
the session uses it's own arena allocator as well, so the actuall values needed to compute the node will be ephemeral

1577068148
cshenton
Tensorflow's GPU backend will probably have something like that, I know tensorflow dominates your GPU memory, so they probably use an arena.

1577068189
adamkowalski
the actual backprop computations are pretty tricky haha. I might study how ChainRules.jl works to find out the derivative of everything is

1577068207
cshenton
Even if you're using a static graph, I think you'll make your life easy to use dual numbers.

1577068222
adamkowalski
dual numbers are great for forward mode auto diff

1577068241
adamkowalski
reverse mode auto diff scales better if the number of outputs is small but the number of inputs is large

1577068244
adamkowalski
I think we should have both though

1577068253
adamkowalski
what are your thoughts on graph mode anyway?

1577068308
cshenton
So in terms of cutting edge stuff there's a push towards autodiff being a language level thing.

1577068318
cshenton
i.e. autodiff happens on IR inside the compiler

1577068325
adamkowalski
right like Zygote.jl

1577068329
cshenton
pytorch are doing this with torchscript, and julia with zygote

1577068330
cshenton
yup

1577068345
adamkowalski
torchscript and tf.function both seem to be just jit compiles though

1577068360
adamkowalski
it seems like the trend moved away from graphs, but now we're trying to add them back, just under the hood

1577068367
adamkowalski
julia is a HUGE pain to deploy

1577068387
adamkowalski
and deploying tensorflow/pytorch is all pretty much getting a trace of your program -> creating a graph -> exporting and reading in C++

1577068398
adamkowalski
so I figured let's just use the graph in the first place haha

1577068443
cshenton
That's not unreasonable, this split between what's convenient for research vs. deployment is pretty fundamental.

1577068462
adamkowalski
right, unless we can get andrewrk to help us build something like this into the compiler itself

1577068478
adamkowalski
but I think the explicit nature of this approach has advantages

1577068493
adamkowalski
each time you create an operation it allocates, which may fail, so you need to "try" it

1577068501
adamkowalski
and executing the graph allocates so same goes

1577068513
adamkowalski
also since shapes are known at runtime (for now) they may mismatch, which may fila

1577068515
adamkowalski
fail*

1577068522
cshenton
So I've seen teams attempt to roll their own graph autodiff framework before.

1577068530
cshenton
In java

1577068564
cshenton
And they really struggled because they sort of went halfway on ergonomics and performance and got the worst of both worlds.

1577068582
adamkowalski
I care a lot about reliability, and scalability. I think that matters much more then prototyping. Plus I think it's not that bad to write models even with this explicit API

1577068604
adamkowalski
I just forces you to think about allocation, failure, and types

1577068617
cshenton
For sure

1577068635
adamkowalski
We have all these models currently written in Python and it's a huge pain to refactor

1577068650
cshenton
So the place where current frameworks fail is definitely things like compilation / startup time.

1577068652
adamkowalski
there is no compiler so when you add a parameter to a function or remove one, how do you find all the places in your code that it is used

1577068667
adamkowalski
we just hope our unit test catches it

1577068669
cshenton
The push towards dynamic graphs is really about improving developer iteration times.

1577068684
adamkowalski
right, but I disaggree with the premise

1577068694
adamkowalski
I think that then you end up with a bunch of code which maybe you got out the door slightly faster

1577068715
adamkowalski
but just like dynamic typing vs static typing, the tracer baced approaches are harder to maintain in my opinion

1577068744
adamkowalski
development slows down as you increase the number of lines of code, and intent is lost because you don't have the documentaiton that types / shapes can provide

1577068745
cshenton
I agree, my point was that a graph computation framework in zig would have that as a key value-add.

1577068779
cshenton
Good iteration times without things being hard to debug at scale.

1577068796
adamkowalski
I hope so! hopefully as I work on this more and more you and others can keep reviewing the code and making sure you like the direction

1577068852
cshenton
I'd be keen to keep an eye on it, I'm using zig for games engine stuff primarily, but I used to do a lot of probabilistic programming stuff so I'm quite familiar with these kinds of weird scientific computing use cases.

1577068883
adamkowalski
probabilistic programming is definitily a huge use case. being able to backprop through a distribution is really important

1577068899
adamkowalski
in tensorflow that was a huge pain, but you could solve it with the reparametization trick

1577068915
adamkowalski
i don't think you can do that in Julia yet either

1577068921
cshenton
Yeah tensorflow-probability fixed a lot of that.

1577068943
adamkowalski
true, honestly I like a lot of things about tensorflow, I just don't like that it's in Python haha

1577068964
cshenton
I personally think the pytorch c++ apis are really nice. They factored them out really well.

1577068978
adamkowalski
I think we can do better though

1577068980
cshenton
Well the difficulty with backprop through samplers / likelihoods is that writing them in autodiff friendly form is awkward.

1577068985
adamkowalski
they use shared pointer everywhere

1577068990
cshenton
oof

1577069005
adamkowalski
it's reference semantics which doesn't make sense in C++ which is so value oriented

1577069026
adamkowalski
They claim it's because it helps the Python data scientists transition

1577069085
adamkowalski
another use case we want to support is differential equations, just like Julia. It works so well with Flux

1577069148
adamkowalski
but first thing is first. I just want a simple "dense/linear/affine" layer that I can backprop through and use that to solve MNIST

1577069163
adamkowalski
then write a simple article about why Zig for machine learning, and get people excited and contributing

1577069184
adamkowalski
then we can do convolutions, lstms, and attention mechanisms

1577069187
cshenton
One thing to keep in mind is that the existing frameworks are the way they are not because the engineers were bad.

1577069197
cshenton
But because the users want a particular interface.

1577069228
adamkowalski
oh no I definitely agree with that, I think everyone working on those projects is doing an amazing job

1577069240
cshenton
So I guess the question is, who are the users who want this kind of API for graph computation? It might be they're in a particular field, so focussing on features in that field would be the way to go.

1577069242
adamkowalski
I think we have the benefit of hindsight and not needing to be backwards compatible though

1577069311
adamkowalski
I think the users of this API want something that is meant for production rather then research

1577069332
adamkowalski
however, I am hoping the API will be pleasant enough that you can still use it for research

1577069351
adamkowalski
i'm not sure there must be this clear distinction, I guess you could just argue it's slightly less ergonomic

1577069376
adamkowalski
but it will make sure that you handle all possible error conditions, and when you need to extend it, you don't need to drop into a lower level language

1577069420
adamkowalski
finally you can deploy it without needing swift, javascript, java, etc as you can just use web assembly or if you target the C ABI you can have much greater reach

1577077944
cshenton
adamkowalski: One thing you could do is to target your zig library as a backend for

1577077951
cshenton
Because then you could have a user story like: transition your existing models using this path, and start writing new models with the front end inside the library itself.

1577077955
cshenton
Either way, I think it's a compelling use case. Even a replacement for the tensorflow c++ api that isn't a nightmare to build would be a huge value add for a lot of use cases.

1577077960
cshenton
Also here's the updated arrayInfo that works with slices as well as arrays. You should also decide if you consider Vectors to be a container type or an integral type.

1577120108
Snektron
Ah, an uni assignment with which you can pick the language

1577120119
Snektron
You know what that means

1577120288
leeward
whitespace?

1577120340
mq32
Malbolge?

1577120359
leeward
Y

1577120389
Snektron
I did hand in assembly at some point

1577120407
leeward
What architecture?

1577120417
Snektron
x86

1577120433
Snektron
The assignment was to make a simple shell in C

1577120907
mq32
const uint8_t code[] = "\x11…"; int main() { return ((int(*)())code)(); }

1577120909
mq32
:D

1577121019
leeward
C is good for defeating its own purpose.

1577121156
mq32
oh yeah

1577121235
leeward
Though that's machine code, not assembler language.

1577121688
leeward
/pedant

1577121943
fengb
mq32: are you casting a string literal to a function pointer?

1577121967
mq32
fengb: yeah, so? :D

1577121971
mq32
that's called "inline machine code" :D

1577122296
Snektron
That shouldnt work

1577122309
Snektron
Unless you have some system without virtual memory that is

1577125321
Snektron
How long are static builds hosted on ziglang.org/builds?

1577125330
Snektron
apart from major versions

1577126882
leeward
Snektron: Why wouldn't it work with virtual memory?

1577126909
hoppetosse
would it be feasible to have the compiler output the actual active field on "access of inactive union field" safety check?

1577126929
hoppetosse
*not compiler, stacktrace

1577127572
fengb
leeward: most OSs mark data separately from executable code so that’d most likely segfault when trying to execute data

1577127818
leeward
fengb: Oh, so not virtual memory.

1577127863
leeward
Yeah, I know about NX bits.

1577127993
leeward
It's more of a pain, but NX can be cleared on .bss.

1577128114
leeward
Or whatever page table entry holds .bss, anyway.

1577130649
leeward
Whoo, LoggingAllocator really doesn't work, does it?

1577132673
lygaret
hey, if I have a slice of bytes, of a known length, is there a way to cast that to an array of the same length? I'm trying to use `std.mem.bytesAsValue(Header, &data[8..16])`, but I'm getting a compile error of: `error: expected *[N]u8 , passed [*]const u8`

1577132723
lygaret
er:  `expected *[N]u8 , passed *[]const u8` (prev was from trying `data[8..16].ptr`)

1577132754
lygaret
it seems I'm missing something, but I'm having trouble figuring out why these wouldn't be the same type?

1577133344
fengb
Slices don’t cast back to arrays yet:

1577133677
lygaret
@fengb, that's perfect thank you - didn't think to look at the bug tracker, and there's a good workaround in the comments there

1577133682
lygaret
appriciated

1577134280
fengb
np

1577136458
Snektron
<leeward "Snektron: Why wouldn't it work w"> Because i expect static data to be in read/write memory and not in executable memory

